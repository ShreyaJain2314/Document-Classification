{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50704202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bank statement</td>\n",
       "      <td>page 10f5 03/02/2022 dc 1090001004230 gs anyco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>invoice</td>\n",
       "      <td>anycompany retail services date mar26,2018_ ll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>invoice</td>\n",
       "      <td>anycompany llc 7688 florencio causeway millsbu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bank statement</td>\n",
       "      <td>page 1of5 03/02/2022 dc 1090001004290, ge anyc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bank statement</td>\n",
       "      <td>page 10f5 03/02/2022 dc 1090001004290 . 999999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>invoice</td>\n",
       "      <td>anycompany dealers date jun 20, 2018 85899 her...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>business proof</td>\n",
       "      <td>nagaswara hhusie publishing surat keterangan k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>invoice</td>\n",
       "      <td>anycompany hardware date jan 20, 2020 s s invo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>address proof</td>\n",
       "      <td>affidavit of residence . application implement...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>bank statement</td>\n",
       "      <td>page 10f5 03/02/2022 dc 1090001004290 99999999...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>347 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Tag                                               Text\n",
       "0    bank statement  page 10f5 03/02/2022 dc 1090001004230 gs anyco...\n",
       "1           invoice  anycompany retail services date mar26,2018_ ll...\n",
       "2           invoice  anycompany llc 7688 florencio causeway millsbu...\n",
       "3    bank statement  page 1of5 03/02/2022 dc 1090001004290, ge anyc...\n",
       "4    bank statement  page 10f5 03/02/2022 dc 1090001004290 . 999999...\n",
       "..              ...                                                ...\n",
       "342         invoice  anycompany dealers date jun 20, 2018 85899 her...\n",
       "343  business proof  nagaswara hhusie publishing surat keterangan k...\n",
       "344         invoice  anycompany hardware date jan 20, 2020 s s invo...\n",
       "345   address proof  affidavit of residence . application implement...\n",
       "346  bank statement  page 10f5 03/02/2022 dc 1090001004290 99999999...\n",
       "\n",
       "[347 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data=pd.read_csv(\"trainingdata.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f13b66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "import sklearn\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84f612e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bank statement' 'invoice' 'receipt' 'salary slip' 'employment proof'\n",
      " 'address proof' 'tax return' 'business proof' 'fund raising']\n"
     ]
    }
   ],
   "source": [
    "target_category = data['Tag'].unique()\n",
    "print(target_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14370424",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tagId']= data['Tag'].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ed3401c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>tagId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bank statement</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>invoice</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>receipt</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>salary slip</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>employment proof</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>address proof</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>tax return</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>business proof</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>fund raising</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Tag  tagId\n",
       "0     bank statement      0\n",
       "1            invoice      1\n",
       "6            receipt      2\n",
       "8        salary slip      3\n",
       "9   employment proof      4\n",
       "22     address proof      5\n",
       "79        tax return      6\n",
       "93    business proof      7\n",
       "98      fund raising      8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_category = data[[\"Tag\",\"tagId\"]].drop_duplicates().sort_values('tagId')\n",
    "tag_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5961ec9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SJain\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\SJain\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\SJain\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\SJain\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\SJain\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9262616",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=data[\"Text\"]\n",
    "category=data[\"Tag\"]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(text,category, test_size = 0.3, random_state = 60,shuffle=True, stratify=category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2815385d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70b37f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Train Accuracy Score : 100% \n",
      "SVM Test Accuracy Score  : 94% \n",
      "\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "  bank statement       0.67      0.50      0.57         4\n",
      "         invoice       1.00      1.00      1.00        32\n",
      "         receipt       1.00      0.25      0.40         4\n",
      "     salary slip       0.50      1.00      0.67         1\n",
      "employment proof       0.00      0.00      0.00         0\n",
      "   address proof       1.00      1.00      1.00        30\n",
      "      tax return       0.90      1.00      0.95        28\n",
      "  business proof       1.00      0.75      0.86         4\n",
      "    fund raising       1.00      1.00      1.00         2\n",
      "\n",
      "        accuracy                           0.94       105\n",
      "       macro avg       0.79      0.72      0.72       105\n",
      "    weighted avg       0.96      0.94      0.94       105\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SJain\\V_env\\V1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SJain\\V_env\\V1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SJain\\V_env\\V1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "sgd.fit(X_train,Y_train)\n",
    "\n",
    "test_predict = sgd.predict(X_test)\n",
    "\n",
    "train_accuracy = round(sgd.score(X_train,Y_train)*100)\n",
    "test_accuracy =round(accuracy_score(test_predict, Y_test)*100)\n",
    "\n",
    "\n",
    "print(\"SVM Train Accuracy Score : {}% \".format(train_accuracy ))\n",
    "print(\"SVM Test Accuracy Score  : {}% \".format(test_accuracy ))\n",
    "print()\n",
    "print(classification_report(test_predict, Y_test, target_names=target_category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52ade90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pytesseract import pytesseract\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "def text_extraction(image_path):\n",
    "    path_to_tesseract = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "#image_path = r\"bank1.png\"\n",
    "    #image_path=\"C:\\Users\\SJain\\Documents\\samples\\bank statements\\\"\n",
    "# Opening the image & storing it in an image object\n",
    "    img = Image.open(image_path)\n",
    "\n",
    "# Providing the tesseract executable\n",
    "# location to pytesseract library\n",
    "    pytesseract.tesseract_cmd = path_to_tesseract\n",
    "\n",
    "# Passing the image object to image_to_string() function\n",
    "# This function will extract the text from the image\n",
    "    text = pytesseract.image_to_string(img)\n",
    "    text=text.replace(\"\\n\\n\",\" \").replace(\"[\",\"\").replace(\"-\",\"\").replace(\".â€”\",\"\").replace(\"|\",\"\").replace(\":\",\"\")\n",
    "    text=text.replace(\"|\",\"\").replace(\"Â§\",\"\").replace(\"@\",\"\").replace(\"Â¥\",\"\").replace(\"Â©\",\"\")\n",
    "    text=text.replace(\"Â«\",\"\")\n",
    "    text=text.replace(\"\\n\",\" \")\n",
    "    text=text.replace(\">\",\"\")\n",
    "# Displaying the extracted text\n",
    "    #print(text[:-1])\n",
    "    \n",
    "    l=[]\n",
    "    text_tokens = word_tokenize(text)\n",
    "    tokens_without_sw = [word for word in text_tokens if not word in stopwords.words()]\n",
    "    #print(tokens_without_sw)\n",
    "    l.append(tokens_without_sw)\n",
    "    l2=[]\n",
    "    for i in l:\n",
    "        r=TreebankWordDetokenizer().detokenize(i)\n",
    "        l2.append(r)\n",
    "    lst=[]\n",
    "    ps = PorterStemmer()\n",
    "    for i in l2:\n",
    "    #text_tokens = word_tokenize(i)\n",
    "    #tokens_without_sw = [word for word in text_tokens if not word in stopwords.words()]\n",
    "        res=ps.stem(i)\n",
    "   # res=res.replace(\" | \",\" \")\n",
    "    #res = i.translate(remove_digits)\n",
    "        lst.append(res)\n",
    "    df1 = {\n",
    "        'Text' :lst\n",
    "    }\n",
    " \n",
    "    df1 = pd.DataFrame(df1,columns=['Text'])\n",
    "    #print(df1)\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1484408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "re1=text_extraction(\"receipt_99.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5ee485e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the aiml store 1234 somewhere . rd poway, cali...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0  the aiml store 1234 somewhere . rd poway, cali..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38471564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    the aiml store 1234 somewhere . rd poway, cali...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text=re1[\"Text\"]\n",
    "test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26aa2d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prdict = sgd.predict(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2b291e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['receipt'], dtype='<U16')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9595996b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.4379115 , -1.15549847, -1.24008727, -1.44097604, -1.21432172,\n",
       "        -1.59526261,  1.62084989, -1.25457788, -1.11036233]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict_prob=sgd.decision_function(test_text)\n",
    "y_predict_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd70b08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "V1",
   "language": "python",
   "name": "v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
